{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de4547-84f2-41a9-ad1e-4dbb80f01116",
   "metadata": {},
   "source": [
    "#### FTP(IIS)のログを解析する\n",
    "##### IN : IIS(FTP)のログ置き場にSMBで取得、必要情報\n",
    "##### OUT:\n",
    "\n",
    "https://sinhrks.hatenablog.com/entry/2014/11/21/231534"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c68a3-3482-4d30-9cb4-36fab0cf68c1",
   "metadata": {},
   "source": [
    "###### 必要ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d631a9-8877-4726-a6f1-898ed0018793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysmb in /opt/conda/lib/python3.9/site-packages (1.2.7)\n",
      "Requirement already satisfied: pyasn1 in /opt/conda/lib/python3.9/site-packages (from pysmb) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc05d04-cc45-45ff-a6b9-add5e76ccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smb.SMBConnection import SMBConnection\n",
    "import platform\n",
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "#from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import typer\n",
    "#import os\n",
    "import gc\n",
    "\n",
    "#import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0425f382-1916-40ac-8efc-93005d6d234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global order\n",
    "order = [\n",
    "        \"date\",\"time\",\"c-ip\",\"cs-username\",\"s-ip\",\n",
    "        \"s-port\",\"cs-method\",\"cs-uri-stem\",\"sc-status\",\"sc-win32-status\",\n",
    "        \"sc-substatus\",\"time-taken\",\"x-session\",\"x-fullpath\"\n",
    "    ]\n",
    "\n",
    "global FILE_NUMBER\n",
    "FILE_NUMBER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823b2b49-c845-471a-9c29-78586a3ee4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envset(argLOG_YMD, argYMD):\n",
    "    global ENV\n",
    "    global ip_address\n",
    "    global user\n",
    "    global password\n",
    "    global remote_hostname \n",
    "    global LOG_YMD\n",
    "    global SHARE_NAME\n",
    "    global FILE_TO_PATH\n",
    "    global HOME_PATH\n",
    "    global OUT_PATH\n",
    "    global LOG_PATH\n",
    "    global YMD\n",
    "    global OUT_FILE\n",
    "    global picklepath\n",
    "    global OUT_SUM_FILE\n",
    "    \n",
    "    LOG_YMD = argLOG_YMD\n",
    "    ENV = 'HONBAN'    \n",
    "    #ENV = 'TEST'\n",
    "    if(ENV == 'TEST'):\n",
    "        ip_address = '172.30.9.85'\n",
    "        user = 'Administrator'\n",
    "        password = 'panic'\n",
    "        remote_hostname = 'RGSV920'\n",
    "    else:\n",
    "        ip_address = '172.30.4.193'\n",
    "        user = 'Administrator'\n",
    "        password = 'panic'\n",
    "        remote_hostname = 'SESV400'\n",
    "\n",
    "    SHARE_NAME = 'd$'\n",
    "    FILE_TO_PATH = 'Ftp/Logs/2021/'\n",
    "    HOME_PATH = '/home/jovyan/'\n",
    "    OUT_PATH = HOME_PATH + 'datasets/Ftplogs/Output/'\n",
    "    LOG_PATH = f'{HOME_PATH}datasets/Ftplogs/{remote_hostname}/'\n",
    "    #YMD = f'%s' % dt.datetime.now().strftime('%Y%m%d')\n",
    "    YMD = argYMD\n",
    "    #\n",
    "    #OUT_FILE = f'{OUT_PATH}Log/{YMD}_{remote_hostname}_{LOG_YMD}_{FILE_NUMBER}_FtpLogs.csv'\n",
    "    #picklepath = f'{OUT_PATH}Pickle/{YMD}_{remote_hostname}_{LOG_YMD}_{FILE_NUMBER}_FtpLogs.csv.pickle'\n",
    "    #OUT_SUM_FILE = f'{OUT_PATH}Sumary/{YMD}_{remote_hostname}_{LOG_YMD}_{FILE_NUMBER}_FtpLogsSumary.csv'\n",
    "    \n",
    "    print(f'%-20s:{ENV:<15s}' % (\"ENV\"))\n",
    "    print(f'%-20s:{ip_address:<15s}' % (\"ip_address\"))\n",
    "    print(f'%-20s:{user:<15s}' % (\"user\"))\n",
    "    print(f'%-20s:{password:<15s}' % (\"password\"))\n",
    "    print(f'%-20s:{remote_hostname:<15s}' % (\"remote_hostname\"))\n",
    "    print(f'%-20s:{SHARE_NAME:<15s}' % (\"SHARE_NAME\"))\n",
    "    print(f'%-20s:{OUT_PATH:<15s}' % (\"OUT_PATH\"))\n",
    "    print(f'%-20s:{LOG_PATH:<15s}' % (\"LOG_PATH\"))\n",
    "    print(f'%-20s:{YMD:<15s}' % (\"YMD\"))\n",
    "    print(f'%-20s:{LOG_YMD:<15s}' % (\"LOG_YMD\"))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62dad9a-af61-48f1-8450-38bd3369eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filenames(argFILE_NUMBER):\n",
    "    \n",
    "    global OUT_FILE\n",
    "    global picklepath\n",
    "    global OUT_SUM_FILE\n",
    "    \n",
    "    OUT_FILE = f'{OUT_PATH}Log/{YMD}_{remote_hostname}_{LOG_YMD}_{argFILE_NUMBER:02}_FtpLogs.csv'\n",
    "    picklepath = f'{OUT_PATH}Pickle/{YMD}_{remote_hostname}_{LOG_YMD}_{argFILE_NUMBER:02}_FtpLogs.csv.pickle'\n",
    "    OUT_SUM_FILE = f'{OUT_PATH}Sumary/{YMD}_{remote_hostname}_{LOG_YMD}_FtpLogsSumary.csv'\n",
    "    \n",
    "    print(f'%-20s:{OUT_FILE:<15s}' % (\"OUT_FILE\"))\n",
    "    print(f'%-20s:{picklepath:<15s}' % (\"picklepath\"))\n",
    "    print(f'%-20s:{OUT_SUM_FILE:<15s}' % (\"OUT_SUM_FILE\"))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bba5c65-2058-43aa-9590-6c8073db6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def SMBFileList():\n",
    "    print(\"==================================================\")\n",
    "    result = False\n",
    "    conn = SMBConnection(\n",
    "        user,\n",
    "        password,\n",
    "        platform.uname().node,\n",
    "        remote_hostname,\n",
    "        domain='WORKGROUP',\n",
    "        use_ntlm_v2=True)\n",
    "    result = conn.connect(ip_address, 139)\n",
    "    return result, conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9a6141-61b9-4089-9ff9-6d9702eed8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRead(filename, arg1):\n",
    "    #df =pd.DataFrame(columns = order)\n",
    "    def proc1(lines):\n",
    "        cnt = 0\n",
    "        all = len(lines)\n",
    "        bar_template = \"\"\n",
    "        for buf in lines:\n",
    "            cnt+=1\n",
    "            print(f'\\r{filename:_<10}:{cnt:07}/{all:07} [{cnt/all:.2%}]', end=\"\")\n",
    "            _line = buf.decode() if arg1 == 1 else buf\n",
    "            if not re.search('^#', _line):\n",
    "                (\n",
    "                    date,time,cip,csusername,sip,\n",
    "                    sport,csmethod,csuristem,scstatus,scwin32status,\n",
    "                    scsubstatus,timetaken,xsession,xfullpath\n",
    "                ) = _line.split(' ')\n",
    "                df.loc[len(df)] = [\n",
    "                    date,time,cip,csusername,sip,\n",
    "                    sport,csmethod,csuristem,scstatus,scwin32status,\n",
    "                    scsubstatus,timetaken,xsession,xfullpath\n",
    "                ]\n",
    "    def proc2(filepath):\n",
    "        txt = Path(filepath).resolve()\n",
    "        length = sum(1 for row in open(txt, 'r'))\n",
    "        chunksize = 5000\n",
    "        df_t = pd.DataFrame()\n",
    "        typer.secho(f\"Reading file: {txt}\", fg=\"red\", bold=True)\n",
    "        #typer.secho(f\"total rows: {length}\", fg=\"green\", bold=True)\n",
    "        with tqdm(total=length, desc=\"chunks read: \") as bar:\n",
    "            dsz = length\n",
    "            for i, chunk in enumerate(pd.read_csv(txt, \n",
    "                                                  chunksize=chunksize, \n",
    "                                                  low_memory=False, \n",
    "                                                  header = None, \n",
    "                                                  #skiprows=4, \n",
    "                                                  comment='#',\n",
    "                                                  sep=' ', \n",
    "                                                  names=order,\n",
    "                                                  parse_dates={'timestamp':['date', 'time']}\n",
    "                                                  )):\n",
    "                df_t = pd.concat([df_t,chunk])\n",
    "                bar.update(min(dsz, chunksize))\n",
    "                dsz -= chunksize\n",
    "        #typer.secho(\"end of reading chunks...\", fg=typer.colors.BRIGHT_RED, end=\"\")\n",
    "        #typer.secho(f\"Dataframe length:{len(df_t)}\", fg=\"green\", bold=True)\n",
    "        return df_t\n",
    "    if(arg1 == 1):\n",
    "        # 遅いので使わない\n",
    "        with io.BytesIO() as file:\n",
    "            conn.retrieveFile(SHARE_NAME, FILE_TO_PATH + filename, file)\n",
    "            file.seek(0)\n",
    "            proc1(file.read().splitlines())\n",
    "        file.close()\n",
    "    elif(arg1 == 2):\n",
    "        # 遅いので使わない\n",
    "        with open(LOG_PATH + filename) as file:\n",
    "            proc1(file.read().splitlines())\n",
    "        file.close()\n",
    "    elif(arg1 == 3):\n",
    "        df = proc2(LOG_PATH + filename)\n",
    "        #df = pd.read_csv(LOG_PATH + filename, header = None, skiprows=4, sep=' ', names=order)\n",
    "        #return df\n",
    "        #df_res = pd.concat([df_res, df])\n",
    "        #print(\"--------------------------- concat \")\n",
    "        #print(df_res.dtypes)\n",
    "    else:\n",
    "        print(2)        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a508c5-3797-4a33-b8ee-d96dd3c0a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogWrite(filename, conn):\n",
    "    with open(LOG_PATH + filename, 'wb') as file:\n",
    "        conn.retrieveFile(SHARE_NAME, FILE_TO_PATH + filename, file)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fca6b94c-6521-4e46-906b-afd8713f2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argLOG_YMD, argYMD = f'%s' % dt.datetime.now().strftime('%Y%m%d')):\n",
    "    #LOG_YMD = argLOG_YMD\n",
    "    envset(argLOG_YMD, argYMD)\n",
    "\n",
    "    #SMBコネクション生成\n",
    "    #ret, conn = SMBFileList()\n",
    "    ret ,conn = SMBFileList()\n",
    "    assert ret == True\n",
    "\n",
    "    #SMBファイル一覧\n",
    "    #items = []\n",
    "    items = conn.listPath(\n",
    "        SHARE_NAME,\n",
    "        FILE_TO_PATH\n",
    "    )\n",
    "    assert len(items) > 0\n",
    "            \n",
    "    #FTPログヘッダー\n",
    "    #order = [\n",
    "    #    \"date\",\"time\",\"c-ip\",\"cs-username\",\"s-ip\",\n",
    "    #    \"s-port\",\"cs-method\",\"cs-uri-stem\",\"sc-status\",\"sc-win32-status\",\n",
    "    #    \"sc-substatus\",\"time-taken\",\"x-session\",\"x-fullpath\"\n",
    "    #]\n",
    "    #FTPログDataFrame\n",
    "    df_res = pd.DataFrame(columns = order)\n",
    "    df_concat = pd.DataFrame()\n",
    "    \n",
    "    def proc1(argfilename, df_concat, df_res, OUT_FILE):\n",
    "        df_concat = pd.concat([df_concat, df_res])\n",
    "        df_concat = df_concat.drop(['date','time'], axis=1) \n",
    "        #print(OUT_FILE)\n",
    "        df_concat.index = pd.DatetimeIndex(df_concat.timestamp, name='timestamp')\n",
    "        df_concat.index = df_concat.index.tz_localize('UTC')\n",
    "        df_concat.index = df_concat.index.tz_convert('Asia/Tokyo')\n",
    "        df_concat.timestamp = df_concat.index\n",
    "        df_concat = df_concat.reset_index(drop=True)\n",
    "        df_concat.to_csv(OUT_FILE)\n",
    "        #print(df_concat.info())\n",
    "        df_concat.to_pickle(picklepath)\n",
    "        \n",
    "    FILE_NUMBER = 0\n",
    "    FILE_SIZE = 300000000\n",
    "    FILE_SIZE_CUR = 0\n",
    "    filenames(FILE_NUMBER)\n",
    "    \n",
    "    for item in items:\n",
    "        if(not item.isDirectory and \n",
    "            re.search(LOG_YMD, item.filename)):\n",
    "            #print(f'%s %d bytes' % (item.filename, item.alloc_size)) \n",
    "            FILE_SIZE_CUR += item.alloc_size\n",
    "            if(int(FILE_SIZE_CUR/FILE_SIZE) > 0):\n",
    "                FILE_NUMBER += 1\n",
    "                FILE_SIZE_CUR = item.alloc_size\n",
    "                proc1(item.filename, df_concat,df_res, OUT_FILE)\n",
    "                df_res = df_res[:0]\n",
    "                df_concat = df_concat[:0]\n",
    "                gc.collect()                \n",
    "                \n",
    "            filenames(FILE_NUMBER)\n",
    "            LogWrite(item.filename, conn)\n",
    "            df_res = pd.concat([df_res, LogRead(item.filename, 3)])\n",
    "            \n",
    "    conn.close()\n",
    "    \n",
    "    proc1(item.filename, df_concat,df_res, OUT_FILE)\n",
    "    df_res = df_res[:0]\n",
    "    df_concat = df_concat[:0]\n",
    "    gc.collect()                \n",
    "    return FILE_NUMBER\n",
    "    #assert 0 > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9141642f-8bea-48e3-9087-6e6b9457f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recov(FILE_NUMBER, argLOG_YMD, argYMD = f'%s' % dt.datetime.now().strftime('%Y%m%d')):\n",
    "    envset(argLOG_YMD, argYMD)\n",
    "    filenames(FILE_NUMBER)\n",
    "    #picklepath = f'{OUT_PATH}{YMD}_{remote_hostname}_{argLOG_YMD}_FtpLogs.csv.pickle'\n",
    "    with open(picklepath, mode='rb') as fp:\n",
    "        df_concat = pickle.load(fp)\n",
    "    \n",
    "    df_concat['index'] = df_concat.reset_index().index\n",
    "    print(len(df_concat['x-session'].unique()))\n",
    "    df_min = df_concat.groupby('x-session', as_index=False)[['index','timestamp']].min()\n",
    "    df_max = df_concat.groupby('x-session', as_index=False)[['index','timestamp']].max()\n",
    "    df_min = df_min.rename(columns={'index':'index_min', 'timestamp':'timestamp_min'})\n",
    "    df_max = df_max.rename(columns={'index':'index_max', 'timestamp':'timestamp_max'})\n",
    "    df2 = pd.merge(df_min,df_max, on='x-session')\n",
    "    \n",
    "    df_group = df_concat.groupby(['x-session','c-ip','s-ip'], as_index=False)[['index']].min()\n",
    "    #print(df_group.info())\n",
    "    \n",
    "    df3 = pd.merge(df2,df_group, on='x-session')\n",
    "\n",
    "    df3['timestamp_diff'] = df3['timestamp_max'] - df3['timestamp_min']\n",
    "    #df3['timestamp_ts'] = df3['timestamp_diff'].map(lambda x: x.total_seconds())\n",
    "    df3['timestamp_ts'] = df3['timestamp_diff'].dt.total_seconds() + 1\n",
    "    #display(df3)\n",
    "    df3 = df3.drop(['index','timestamp_diff'], axis=1) \n",
    "    df3['timestamp'] = df3['timestamp_min'].dt.strftime('%Y/%m/%d %H:%M:%S')\n",
    "    df3['count'] = 1\n",
    "    #\n",
    "    print(df3.info())\n",
    "    ##df3.to_csv(OUT_SUM_FILE)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a278b4f-efef-4c28-a2f5-f2d428fc8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(df3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import collections\n",
    "    import itertools\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    # matplotlib日本語化対応\n",
    "    import japanize_matplotlib\n",
    "\n",
    "    all_from_list = df3['c-ip'].tolist()\n",
    "    c = collections.Counter(df3['c-ip'].tolist())\n",
    "\n",
    "    tags = pd.Series(c)\n",
    "    #print(tags)\n",
    "    df4 = df3.copy()\n",
    "    df4.set_index('timestamp_min', inplace=True)\n",
    "\n",
    "    df_tag_list = []\n",
    "    # 先頭10\n",
    "    top_tag_list = tags.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "    for t in top_tag_list:\n",
    "        print(t)\n",
    "        df_tag = df3[df3['c-ip'].apply(lambda x: t in x)]\n",
    "        df_tag_list.append(df4[['timestamp_ts']].resample('H').sum())\n",
    "\n",
    "    df_tags = pd.concat(df_tag_list, axis=1)\n",
    "    df_tags.columns = top_tag_list\n",
    "\n",
    "    df_tags[:-1].plot(stacked=True,figsize=(10, 4), title='上位10接続推移')\n",
    "    plt.legend(title=\"接続先\", bbox_to_anchor=(1.05, 1)) # <-- ココ\n",
    "    plt.show()\n",
    "\n",
    "    df_tags[:-1].plot.bar(stacked=True, figsize=(10, 4), title='上位10接続推移積み上げ')\n",
    "    plt.legend(title=\"接続先\", bbox_to_anchor=(1.05, 1)) # <-- ココ\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a736b1-816d-45fc-89a4-531cea39d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IN] YMD: 2201\n",
      "ENV                 :HONBAN         \n",
      "ip_address          :172.30.4.193   \n",
      "user                :Administrator  \n",
      "password            :panic          \n",
      "remote_hostname     :SESV400        \n",
      "SHARE_NAME          :d$             \n",
      "OUT_PATH            :/home/jovyan/datasets/Ftplogs/Output/\n",
      "LOG_PATH            :/home/jovyan/datasets/Ftplogs/SESV400/\n",
      "YMD                 :20220329       \n",
      "LOG_YMD             :2201           \n",
      "==================================================\n",
      "OUT_FILE            :/home/jovyan/datasets/Ftplogs/Output/Log/20220329_SESV400_2201_00_FtpLogs.csv\n",
      "picklepath          :/home/jovyan/datasets/Ftplogs/Output/Pickle/20220329_SESV400_2201_00_FtpLogs.csv.pickle\n",
      "OUT_SUM_FILE        :/home/jovyan/datasets/Ftplogs/Output/Sumary/20220329_SESV400_2201_FtpLogsSumary.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lp:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[IN] YMD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#n = 12\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(argLOG_YMD, argYMD)\u001b[0m\n\u001b[1;32m     61\u001b[0m         df_res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_res, LogRead(item\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;241m3\u001b[39m)])\n\u001b[1;32m     63\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 65\u001b[0m \u001b[43mproc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUT_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m df_res \u001b[38;5;241m=\u001b[39m df_res[:\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m df_concat \u001b[38;5;241m=\u001b[39m df_concat[:\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mmain.<locals>.proc1\u001b[0;34m(argfilename, df_concat, df_res, OUT_FILE)\u001b[0m\n\u001b[1;32m     30\u001b[0m df_concat \u001b[38;5;241m=\u001b[39m df_concat\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#print(OUT_FILE)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m df_concat\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(\u001b[43mdf_concat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m df_concat\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_concat\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m df_concat\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_concat\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtz_convert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsia/Tokyo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5581\u001b[0m ):\n\u001b[1;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'timestamp'"
     ]
    }
   ],
   "source": [
    "#lp = ['21010','21011','21012'] #20220323\n",
    "#lp = ['21013','21022','21022'] #20220325\n",
    "#lp = ['21030','21031','21032','21033']  #20220325\n",
    "#lp = ['21040','21041','21042','21043']  #20220325\n",
    "#lp = ['21050','21051','21052','21053']  #20220325\n",
    "#lp = ['21060','21061','21062','21063']  #20220325\n",
    "#lp = ['21070','21071','21072','21073']  #20220325\n",
    "#lp = ['21080','21081','21082','21083']  #20220328\n",
    "#lp = ['21090','21091','21092','21093']  #20220328\n",
    "# #lp = ['21100','21101','21102','21103']  #20220328\n",
    "# #lp = ['21102']  #20220328-1 ['211020','211021','211022','211023','211024','211025']\n",
    "# #lp = ['21102']  #20220328-1 ['211026','211027','211028','211029']\n",
    "# #lp = ['21103']  #20220328\n",
    "#lp = ['2110']  #20220329\n",
    "#lp = ['2111']  #20220329\n",
    "#lp = ['2112']  #20220329\n",
    "lp = ['2201']  #20220329\n",
    "df = pd.DataFrame()\n",
    "for l in lp:\n",
    "    print(f'[IN] YMD: {l}')\n",
    "    n = main(l)\n",
    "    #n = 12\n",
    "    for i in range(n):\n",
    "        df = pd.concat([df, recov(i, l)])\n",
    "        \n",
    "    df.to_csv(OUT_SUM_FILE)\n",
    "    #graph(recov(l, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a731bf2-a0ee-4170-925a-e4bbf2b41edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
